{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso\n",
    "import sklearn\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import sys,os\n",
    "sys.path.append(os.path.abspath(\"/mnt/home/yjo10/ceph/CAMELS/MIEST/utils/\"))\n",
    "from imp import reload \n",
    "# Change in mymodule/'\n",
    "import vib_utils\n",
    "reload(vib_utils)\n",
    "from vib_utils import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Device Config\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu' # temporarily\n",
    "# Fix random seeds for reproducibility\n",
    "seed = 73\n",
    "#torch.manual_seed(seed)\n",
    "#np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(field):\n",
    "    if field == 'Mtot':\n",
    "        fix = \"\"\n",
    "    else:\n",
    "        fix = \"_\"+field\n",
    "    coef = np.load(\"/mnt/home/yjo10/ceph/CAMELS/MIEST/data/wph_nIllustrisTNG{}_for_vib_total.npy\".format(fix))\n",
    "    gcoef_avg = np.zeros((1000, coef.shape[1]))\n",
    "    for i in range(1000):\n",
    "        gcoef_avg[i,:] = coef[i*15:i*15+15,:].mean(axis=0)\n",
    "    coef = np.load(\"/mnt/home/yjo10/ceph/CAMELS/MIEST/data/wph_nSIMBA{}_for_vib_total.npy\".format(fix))\n",
    "    rcoef_avg = np.zeros((1000, coef.shape[1]))\n",
    "    for i in range(1000):\n",
    "        rcoef_avg[i,:] = coef[i*15:i*15+15,:].mean(axis=0)\n",
    "    coef = np.load(\"/mnt/home/yjo10/ceph/CAMELS/MIEST/data/wph_nAstrid{}_for_vib_total.npy\".format(fix))\n",
    "    acoef_avg = np.zeros((1000, coef.shape[1]))\n",
    "    for i in range(1000):\n",
    "        acoef_avg[i,:] = coef[i*15:i*15+15,:].mean(axis=0)\n",
    "    coef = np.r_[gcoef_avg, rcoef_avg, acoef_avg]\n",
    "\n",
    "\n",
    "    fparam = '/mnt/home/fvillaescusa/CAMELS/PUBLIC_RELEASE/CMD/2D_maps/data/params_IllustrisTNG.txt'\n",
    "    gparams = np.loadtxt(fparam)\n",
    "    gparams = gparams[:,:2] ## only Om and Sig8\n",
    "    fparam = '/mnt/home/fvillaescusa/CAMELS/PUBLIC_RELEASE/CMD/2D_maps/data/params_SIMBA.txt'\n",
    "    rparams = np.loadtxt(fparam)\n",
    "    rparams = rparams[:,:2] ## only Om and Sig8\n",
    "    fparam = \"/mnt/home/fvillaescusa/CAMELS/Results/images_Astrid/params_LH_Astrid.txt\" \n",
    "    aparams = np.loadtxt(fparam)\n",
    "    aparams = aparams[:,:2] ## only Om and Sig8\n",
    "    params  = np.r_[gparams, rparams, aparams]\n",
    "    return coef, params\n",
    "\n",
    "def make_dataset(coef,params):\n",
    "    batch_size       = 100\n",
    "    validation_split = .2\n",
    "    shuffle_dataset  = True\n",
    "    random_seed      = 42\n",
    "\n",
    "    # Labelling for classification of simultions\n",
    "    y_params   = torch.tensor(params,dtype=torch.float)\n",
    "    y          = torch.zeros((y_params.shape[0],y_params.shape[1]+3))\n",
    "    y[:,:2]    = y_params\n",
    "    y[0:1000   ,2] = 1.\n",
    "    y[1000:2000,3] = 1.\n",
    "    y[2000:3000,4] = 1.\n",
    "\n",
    "\n",
    "    X = torch.tensor(np.absolute(coef),dtype=torch.float)\n",
    "    dataset      = data_utils.TensorDataset(X, y)\n",
    "    dataset_size = len(dataset)\n",
    "    indices      = list(range(dataset_size))\n",
    "    split        = int(np.floor(validation_split * dataset_size))\n",
    "    if shuffle_dataset :\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader  = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                               sampler=train_sampler)\n",
    "    test_dataset      = data_utils.TensorDataset(X[val_indices], y[val_indices,:2])\n",
    "    return train_loader, test_dataset\n",
    "\n",
    "def print_score(test_dataset, vib, field):\n",
    "    X, y            = test_dataset.tensors\n",
    "    y_pred, y_sigma = vib(torch.tensor(X,dtype=torch.float).to(device))\n",
    "    y_pred          = y_pred.cpu().detach().numpy()\n",
    "    y               = y.cpu().detach().numpy()\n",
    "    rele_om         = np.abs(y[:,0]-y_pred[:,0])/y[:,0]\n",
    "    rele_om         = rele_om.mean()\n",
    "    r2_om           = sklearn.metrics.r2_score(y[:,0],y_pred[:,0])\n",
    "    rele_sig        = np.abs(y[:,1]-y_pred[:,1])/y[:,1]\n",
    "    rele_sig        = rele_sig.mean()\n",
    "    r2_sig          = sklearn.metrics.r2_score(y[:,1],y_pred[:,1])\n",
    "\n",
    "    #print(rele_om)\n",
    "    print(\"{}: Reletive Error=({:.3f}, {:.3f}), R2 score=({:.3f}, {:.3f})\"\\\n",
    "          .format(field,rele_om,rele_sig,r2_om,r2_sig))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mtot: Reletive Error=(0.058, 0.034), R2 score=(0.951, 0.912)\n",
      "Mgas: Reletive Error=(0.094, 0.065), R2 score=(0.888, 0.649)\n",
      "Mstar: Reletive Error=(0.163, 0.091), R2 score=(0.730, 0.357)\n",
      "HI: Reletive Error=(0.050, 0.047), R2 score=(0.970, 0.828)\n",
      "ne: Reletive Error=(0.091, 0.066), R2 score=(0.898, 0.670)\n",
      "Vcdm: Reletive Error=(0.209, 0.102), R2 score=(0.606, 0.240)\n",
      "Z: Reletive Error=(0.175, 0.084), R2 score=(0.696, 0.458)\n",
      "T: Reletive Error=(0.138, 0.093), R2 score=(0.809, 0.329)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "beta   = 1e-3\n",
    "input_shape  = 3105\n",
    "output_shape = 2\n",
    "learning_rate = 1e-3\n",
    "decay_rate = 0.97\n",
    "z_dim = 200\n",
    "epochs = 3000\n",
    "batch_size =100\n",
    "fields =  ['Mtot','Mgas','Mstar','HI','ne','Vcdm','Z','T']\n",
    "\n",
    "for field in fields:\n",
    "    coef, params               = loader(field)\n",
    "    train_loader, test_dataset = make_dataset(coef, params)\n",
    "    vib = NDR(input_shape, output_shape,z_dim, num_models=3)\n",
    "    total_loss, accuracy = train_ndr(vib, train_loader, device, epochs,batch_size,test_dataset, verbose=False)\n",
    "    print_score(test_dataset,vib,field)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Altogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 24840)\n",
      "T: Reletive Error=(0.035, 0.032), R2 score=(0.982, 0.926)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "beta   = 1e-3\n",
    "input_shape  = 3105*8\n",
    "output_shape = 2\n",
    "learning_rate = 1e-3\n",
    "decay_rate = 0.97\n",
    "z_dim = 200\n",
    "epochs = 3000\n",
    "fields =  ['Mtot','Mgas','Mstar','HI','ne','Vcdm','Z','T']\n",
    "\n",
    "\n",
    "for field in fields:\n",
    "    coef, params               = loader(field)\n",
    "    try:\n",
    "        coefall = np.c_[coefall, coef]\n",
    "    except:\n",
    "        coefall = coef\n",
    "print(coefall.shape)\n",
    "        \n",
    "train_loader, test_dataset = make_dataset(coefall, params)\n",
    "vib = NDR(input_shape, output_shape,z_dim, num_models=3)\n",
    "total_loss, accuracy = train_ndr(vib, train_loader, device, epochs,batch_size,test_dataset, verbose=False)\n",
    "print_score(test_dataset,vib,field)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "VIBDemo2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
